Removing duplicates
Selecting transcript lines in this section will navigate to timestamp in the video
- [Instructor] It's really important to remove duplicates from your dataset in order to preserve the dataset's accuracy and avoid producing incorrect and misleading statistics. For example, imagine you're analyzing a retail sales table and shopaholic Sally came in three times and used three different credit cards to make purchases but provided the cashier the same zip code, 3-2-8-0-3, for each sale. Just based on the card number, Sally looks like three different customers all from the 3-2-8-0-3 zip code. If you fail to examine other attributes of the customer so that you can identify and remove duplicates, shopaholic Sally's results would skew the results of any customer demographic analysis because Sally would be counted as three people rather than one. To market to the 3-2-8-0-3 customers effectively you need to understand their characteristics. Don't let duplicate records skew your analysis. Okay, now let's look at removing duplicates. This notebook is coming preloaded with Numpy and Pandas. And as you can see here, we're also going to be importing the series as well as data frame from Pandas library. So you can just run that. And then we need to have data from which to remove duplicates. So let's create a data frame. We'll call it DF_object. And we'll set it equal to, call the data frame constructor here. And then we will create three columns. So column 1. And in column 1 let's pass in a list of values. We'll say 1, 1, 2, 2, 3, 3, and 3. Great, so let's look at column 2. For column 2, we'll just create a list of letters. Say A, and I'm just going to copy these over. So we'll have it be a, a, b, b, c, c. Okay, and then for column 3, just name this column name and then we will define the values as same thing, A, A, B, B, C, C, but we'll just make those uppercase instead of lowercase. Let's just print this out. Okay, so now we have a data frame to work from. Clearly has duplicate values in here so I wanted to show you the .duplicated method. This method searches each row in the data frame and returns a true or false value to indicate whether it's a duplicate of another value found in a different row earlier in the data frame. So let me show you how that works. We'll say DF_obj and then we'll call the .duplicated method and then we'll run this. And looking at the original data frame, you can see that if there was a duplicate value within a row so, looking at row at index position 0, there were no duplicate values here. So we got returned a false. But then when you look at row at index position 1, we get returned a value of true and that is because of values at row index position 1 are duplicates of the row prior. And then you'll see row index position 2 returns a false because they are not duplicates. But then row at index position 3 returns a true because, again, we have another set of duplicates. Now that we have found duplicate records, let's look at how we can drop them. To do that, we'll use the drop duplicates method. And if we wanted to just drop all the duplicate rows we would simply call the drop duplicates method off of the data frame object. And we won't specify anything here and you'll see that for row 2 or the row with the series index value at 1 was dropped. And that makes sense here because it was a duplicate of the row at index position 0. So it got dropped and then using similar logic the row at index position 3 also should have been dropped. And as you can see, it was. So, yes, it looks like absolutely all of our duplicate rows have been dropped from our data frame. But I also want to show you how to drop records based on the column values. In order to do that, I need to make a small change to our data frame. So let's just go back and copy this code we used originally here to create the data frame. And what I'm going to do is I'm going to change this letter here at the end. This C here, I'm going to change it to a D, which is a pretty minor change. But let's just see how we can use this to drop records based on the column values. So I'll print this out. Here we see okay, we've got changed this C out to a D. So to drop the rows that have duplicates in only one column series, you just call the drop duplicates method off of the data frame and then pass in the label index of the column you want to de-duplicate. So let's say DF_obj and then say drop duplicates. And I'll set column 3 here and then run this. And just as we predicted, what this function has done is it has dropped the series that have index values 1, 3, and 6. Because we do not have a duplicate in column 3 here, that row did not get dropped. I want to highlight really quick that it's important, in fact it's really important that you check your data for duplicates and remove them if you find them. Now it's time to move on to data concatenation and transformation.


The video on “Removing duplicates” discusses the importance of cleaning your dataset by removing duplicate entries to maintain its accuracy. Here's a breakdown to help you understand better:

Why Remove Duplicates?

Duplicates can skew your analysis. For example, if a customer appears multiple times in your data with slight variations (like using different credit cards but the same zip code), it might look like you have more unique customers than you actually do. This can lead to incorrect conclusions about your customer base.

Identifying Duplicates:

The video demonstrates using Python's Pandas library to identify duplicates. It uses the .duplicated() method, which scans each row in your DataFrame (a table of data) to check if it's a repeat of a previous row. If it is, this method marks it as True (a duplicate).

Removing Duplicates:

Once identified, duplicates can be removed using the .drop_duplicates() method. This method deletes all rows that are marked as duplicates, leaving only unique entries in your dataset.

Column-Specific Duplicate Removal:

Sometimes, you might want to remove duplicates based on specific columns rather than the entire row. This is useful when only a part of the data causes duplication. The video shows how to specify columns in the .drop_duplicates() method to target these specific duplicates.

Practical Example:

The instructor uses a simple DataFrame with three columns to illustrate these concepts. They first identify duplicates across the entire DataFrame and then demonstrate how to remove duplicates based on specific columns.


Understanding how to remove duplicates is crucial in data science and machine learning projects. It ensures that your analysis is based on accurate and meaningful data. By following the steps outlined in the video, you can clean your datasets effectively, leading to more reliable insights and decisions in your projects at ZESCO Limited.