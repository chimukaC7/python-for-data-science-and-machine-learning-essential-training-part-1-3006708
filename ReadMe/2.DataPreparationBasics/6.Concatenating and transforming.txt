Concatenating and transforming
Selecting transcript lines in this section will navigate to timestamp in the video
- [Voiceover] Knowing how to concatenate and transform data is really important in data analysis. Concatenation and data transformation are useful for getting your data into the structure and order you need for analysis. For example, imagine you're mailing out a piece of direct mail advertisement. You have one table with customer ID and name, and you have another table with customer ID, mailing address, and age. Your mailing address application requires you to supply it only one table that contained only customer name and address. You generate this table by concatenating your two tables by customer ID, row wise. Concatenating is simply combining data from separate sources. Transformation, on the other hand, is converting and reformatting data to the format necessary for your purposes. When you transform your data, you convert it into the format that's required to facilitate analysis. This could include dropping data, which is essentially just dropping variables or observations, can include adding data, which is adding variables and observations, and it also includes sorting data. So, going back to our example, transformation would be when you drop the age column in order to get your data into the exact format that the application would need. Okay, so in this demonstration we're going to look at concatenating and transforming data. And as you can see, the notebook is coming loaded with both pandas and numpy. So, you've got everything set up here, all you need to do is just make sure you run that. And then we'll start first with concatenating data. Before we do anything else, we'd need to create a data frame object, which I'll call "DF_obj" and then call the data frame constructor. And we'll pass the np,arange function, and we will say that we want to create a series of values. Rephrase, and we will say we want to create a series of 36 values, and then we want them to come in the shape of a 6x6. So, we'll say reshape, and then say six rows and six columns. And then if we print this out, you can see, great, we have a series of numbers starting at zero, going to 35, so it's 36 numbers and it's in a 6x6 shape. Now let's create a second data frame. And we'll call it "DF_obj_2" and we'll do the same process here, except for let's just create a series of 15 numbers and then with five rows and three columns, and print that out. Great, perfect. So, now we have something to work with. Let's look at how to concatenate data. To do that, we will use the concat method, which joins data from separate sources and combines them into one combined data table. If you want to join objects based on their row index value you just call the "pd.concat" method on the objects you want joined and then pass in the "axis=1" argument and "axis=1" tells Python to concatenate the data frames by adding columns. In other words, joining on the row index values. So, let's just test that out here. Say "pd.concat" and we'll select our data frame object and our data frame object two, and we'll pass in "axis=1". Now, as you can see, we have gone from having a data frame with... here has six columns, this one has three columns, now we have a data frame with nine columns where data frame object two has been appended or concatenated onto the original data frame object. And in the case where the shapes didn't match up, like at row index position five here, we don't have that row in the second data frame object, and so as you can see, we got missing values returned in that part of the results that were returned to us. Now, if we wanted to do the opposite, and we wanted to join on the column index values, what we could do is we can just either say "axis=0" or we can just completely omit this axis parameter and by default it will join on the column index values. So, I run this, and now you see that the two objects have been concatenated column-wise. Let's look at transforming data really quickly. So first, let's look at dropping data. You can easily drop rows from a data frame by calling the drop method and passing in the index values for the rows you want dropped. So, say "DF_obj" and then ".drop", let's say we want to drop the rows at index position zero and two. We can execute the code here. There was a syntax error where I missed brackets. There we go. Now you see that the rows at index position zero and two have been dropped from my results. Now, if we wanted to go ahead and instead drop the columns at index position zero and two, all you would need to do is pass a parameter that says "axis=1" and run that, and you can see now it's dropped those columns. Let's look now at adding data. So, let's create a series object called "series_obj" and then we'll call the series constructor, we'll pass in the "np.arange" function and we will say we want a series of values from zero to five, we'll want six values. And then let's give this series the name "added_variable". So, to do that we'll say "series_obj.name" and we'll set that equal to "added_variable" and then just print this out to see what it looks like. Okay, great, so it's a series of six numbers that range between zero and five and the series is named "added_variable". Now, you can use the join method to join two data sources into one. By default, the join method works by joining the two sources on their row index values. Let me show you real quick how this works. We will say "variable_added" is equal to... and we'll call "DataFrame.join" function and we will pass in our data frame object and our series object, and then print it out. Ah, look, and then as you can see, our series that we created here called "added_variable" has now been added to the data frame. Now let's try adding data using the concat function. We will create a object called "added_datatable" and we'll set that equal to "pd.concat". Within the concat function, let's pass the "variable_added" object twice. So, we're asking it to concat the "variable_added" data frame to itself, essentially here. And then, let's set the parameter "ignore_index=False" and I'll print this out, and then I'll explain how this will work. "Added_datatable", okay, good. So, what you can see here is it's taken our "variable_added" object that we had, and it's concatenated it to itself. But, because we said this "ignore_index=False" here, what it's done is the index now has duplicates because the original index values from the original object have just been concatenated into the results that were returned. So, if we wanted to reset the index so that it works properly, we would want to then just say "ignore_index=True". And basically what we have done here is we have told pandas to ignore the index of the input data frame and create a new integer index for this resulting data frame. And so, the new index starts at zero, and it increments by one for each row, regardless of what the original index was in the input data frame. The last thing I want to look at here with you is sorting data. To sort rows in the data frame, either in ascending or descending order, you'd need to call the ".sort_values" method off of the data frame and then pass in the by argument to specify the column index upon which the data frame should be sorted. So, let's create a data frame called "DF_sorted" and we'll set it equal to our data frame object, and off of that object we'll call the sort values method, and then we will say we want to sort by our column that is in index position five. So, in order to do that, we would just say "by=[5]" and then if we want it to be in descending order then we just say "ascending=False". And then when we print this out, you can see that our column... our data from our column index position five has been sorted in descending order. So, if we look back at our original data frame, you can see that it was in ascending order and so now the order has been clipped and with that, all of the other values in all of the other columns have also been sorted in that exact same way. And that's about all you need to know about concatenating and transforming data using pandas.



Certainly! Let's dive into the concepts of concatenating and transforming data, which are essential for data analysis and preparation, especially in fields like machine learning and software engineering.

Concatenating data involves combining data from separate sources into one dataset. Imagine you have two lists of customer information: one with names and IDs, and another with IDs and addresses. To send a mail to these customers, you need a single list that includes names and addresses. By concatenating these lists based on customer ID, you merge them into one comprehensive list. This is like zipping two separate sets of files into one folder for easier access.

Transforming data, on the other hand, involves changing the data's format or structure to suit your analysis needs. This could include:

Dropping data: If some information, like age, is not needed for your mailing list, you can remove it to simplify your dataset.
Adding data: You might add new information, such as a column for customer preferences, to enrich your dataset.
Sorting data: Organizing your data based on certain criteria, like alphabetical order of names or ascending order of IDs, to make analysis or operations more straightforward.

In the video, practical examples are provided using Python's pandas library, which is a powerful tool for data manipulation. For instance, you learned how to use the pd.concat method for concatenation and methods like .drop and .sort_values for transformation. These operations are crucial for cleaning and preparing your data, making it ready for further analysis or building machine learning models.

Understanding and applying these techniques will significantly enhance your ability to work with data, allowing you to efficiently prepare datasets for complex analyses or machine learning projects. Given your interest in pivoting to a Machine Learning Engineer role, mastering these skills will be invaluable in your career progression.


