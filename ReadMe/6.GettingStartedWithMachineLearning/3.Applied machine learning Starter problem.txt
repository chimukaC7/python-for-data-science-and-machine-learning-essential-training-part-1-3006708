Applied machine learning: Starter problem
Selecting transcript lines in this section will navigate to timestamp in the video
- [Instructor] Let's dig into the process of preparing a dataset for training a machine learning model. Once we have our dataset ready, we'll proceed to train a fundamental machine learning model using this data we've prepared. The preparation of a dataset for a machine learning models encompasses several steps. Many of which, we've already covered. These include collecting the data, filtering out irrelevant features, and managing existing values. Building on this foundation, the next crucial step is to format the data in a way that makes it suitable for input into a machine learning model. This involves separating the dataset into features, the inputs and labels, the outputs we want to predict. Additionally, the dataset needs to be split into training and validation sets. This partitioning allows for the training of the machine learning model on one subset of the data while the other subset is used for validation. This is helpful for assessing the model's performance and effectiveness. In the coding demonstration I'm about to walk you through, we'll be utilizing various modules from scikit-learn. Initially we'll apply scikit-learn's train test split function to divide our dataset into a training set and a validation set. Following that, we will train a decision tree classifier using our dataset. Lastly, we'll employ scikit-learn's metrics module to assess the performance of our model. Let's get started and see how these steps unfold in practice. I've already imported the required libraries that we will use in this demo. Those are pandas and sklearn. Also, please note that I'm importing metrics from sklearn here, as you can see right here, and that I've preloaded the iris dataset for you that we've been working with earlier demonstrations. Iris is a species of flowering plants. Its dataset contains five columns, which include petal length, petal width, sepal length, sepal width, and species type. We'll try to predict the species type using the other features within the dataset. So let's just start off here by calling the head method off of this dataset. Let me make sure I run this code block here to import our libraries and then we'll call the head method. Give that a chance to run. Okay, great. So this is the basic setup of the data inside of the dataset. These are the first five records. So let's start off by just taking a look at the unique species of iris flowers that are represented within this dataset. To do that, we're going to call the unique method. So we'll say dataset.Species.unique and run this. And what we see here is that there are three types of iris species in this dataset, setosa, versicolor, and virginica. Next, we'll separate features and labels from the dataset. The second, third, fourth, and fifth columns contain features that describe the flower. And the sixth column contains the species labels. First, let's separate the features and save them as an X variable. So we'll say X is equal to dataset.iloc, and then we'll tell it to return all of the rows and only the second through fifth columns. So we'll pass in one through five here and print this out. And what we can see is that the dataset X now contains all of the features from the dataset, but it no longer contains the label, the species label. Now what we need to do is we need to separate the label and save it as a Y variable. So we'll say Y is equal to dataset.iloc. And in this case we want to select all of the rows, but only the sixth column. So we'll pass a five here and then print this out. And as you can see now we have all of the labels, all of the species labels, but then none of the other variables in the dataset. Next, we'll split the features and labels into training and test sets. For this, we'll use sklearn's train test split function. And the training set will be used to train the machine learning model. The test set will be used to test the accuracy of our trained model. Let's write the code. We'll say x_train, x_test, y_train and y_test. These are our placeholders. And then we'll set them equal to the train test split function. So it's train_test_split. And then what we need to do is pass in our variables. So first we're going to pass in our X dataset. Then we'll pass in our target variable, which is Y. In the third parameter, we'll pass in the ratio of the test data from the whole dataset. So here we'll need to say test_size equal to 0.3. And what this means is that 30% of the data will become the test set and 70% of the data will be the training set. And then let's set a seed for a random state. We'll just set random_state equal to zero, and that's so that you get the same results on your screen as we get in the demonstration here, we'll run this. And now it's time to train a decision tree classifier on the training dataset. First we'll create an object of decision tree classifier class. So to do that, we'll say clf is equal to. And then we'll call DecisionTreeClassifier. And then second, we're going to call the fit function. So we'll say clf.fit, and then we'll pass in our x_train and y_train. Run this. Okay, because the Decision tree classifier is now trained, we can use it to predict labels for our test set. To do that, we'll say y_predict, and then we'll set it equal to clf.predict. And we will pass in our x_test here and then print this out. And what you see as a result is that you see all of the predicted labels on the test dataset. The last thing I want to show you how to do is to evaluate our classifiers performance by comparing the predicted labels with the original labels of the test set. We'll use the accuracy metric to evaluate the results. And the function that we'll use is sklearn's accuracy score. So we'll say accuracy is equal to metrics.accuracy_score and we'll pass it in our y_test and our y_predict variable. And then let's just print this out. And when doing so, we'll create a little label here called accuracy, and we're just printing out our accuracy. So just pass that variable in and run. And as you can see, the train model predicted the labels of the test set with more than 90% accuracy.



The video “Applied machine learning: Starter problem” delves into the foundational steps of preparing a dataset for machine learning (ML) and training a basic ML model. Here's a breakdown to help you grasp the key concepts:

Dataset Preparation for ML Models:

Collecting Data: The initial step involves gathering the data you'll use to train your model. This data needs to be relevant to the problem you're trying to solve.

Filtering Out Irrelevant Features: Not all data collected will be useful for your model. This step involves removing unnecessary features (columns) that don't contribute to the model's predictive power.

Managing Missing Values: It's common for datasets to have missing values. These can be handled in various ways, such as filling them with a median value, mean, or removing rows/columns with missing values altogether.

Formatting the Data:

Features and Labels: Separate your dataset into 'features' (inputs) and 'labels' (outputs you want to predict). This is crucial because the model needs to learn the relationship between the inputs and outputs.

Training and Validation Sets: Split your dataset into a training set and a validation set. The model learns from the training set, and its performance is evaluated on the validation set. This helps in assessing how well the model will perform on unseen data.

Training a Decision Tree Classifier:

The video demonstrates using a decision tree classifier, a type of ML model that makes decisions based on asking a series of questions based on the features of the dataset.

Scikit-learn's Train Test Split Function: This function is used to split the dataset into training and validation sets.

Training the Model: After splitting the data, the model is trained on the training set using the .fit() method.

Model Evaluation: Once trained, the model's performance is evaluated on the validation set. The accuracy metric, for example, compares the model's predictions against the actual labels to see how often the model is correct.

Practical Demonstration:

The video provides a hands-on demonstration using the Iris dataset, which includes features like petal length, petal width, sepal length, and sepal width to predict the species of iris flowers.

It walks through the code for splitting the dataset, training the decision tree classifier, and evaluating its performance using scikit-learn's metrics.


Understanding these steps is crucial for anyone looking to pivot into a Machine Learning Engineer role, as they form the basis of most machine learning projects. The process of preparing the data, choosing a model, training, and evaluating it is a cycle that's repeated and refined to achieve the best possible model performance.


