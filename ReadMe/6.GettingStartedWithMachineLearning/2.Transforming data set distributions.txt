Transforming data set distributions
Selecting transcript lines in this section will navigate to timestamp in the video
- [Instructor] The term data transformation refers to the practice of changing data from its original state into a different format. This often includes turning raw data into a format that is clean and ready for use. In this coding demonstration, we're going to explore a variety of beneficial data transformations and look into those scenarios in which they're necessary. We'll focus on two specific data transformation techniques, normalization and standardization. Normalization, also known as min-max scaling is a method where data values are adjusted and scaled to fall within a range of zero to one. This technique maintains the original distribution of values without altering their ranges. On the other hand, standardization is a technique that re-scales data so that it has a mean value of zero and a standard deviation of one. This effectively normalizes the distribution of the data. Keep in mind that in machine learning, not every data set necessitates normalization. It's only required when the features within the data set have varying ranges. The decision to use either normalization or standardization depends on the specific problem at hand and the machine learning algorithm you're using. There is no strict rule that dictates the use of normalization or standardization. A practical approach is to initially feed the machine learning model with raw data, as well as both normalized and standardized versions of the data. By evaluating the performance of the model under these different conditions, one can determine the most suitable type of data transformation for the given scenario. Let's take a look inside of Jupyter. In this demo, I'm going to show you how to transform dataset distributions. As you can see, I've already imported the required libraries that we're going to be using in this demonstration which are numpy, pandas, matplotlib and sklearn. For pre-processing data, we're going to need the MinMaxScaler and the scale from sklearn's preprocessing module. So just pointing out that I have set those and imported them here. So I'm going to run this. And we're going to be using the mtcars data set in this lecture. So I have imported that data set and gotten that ready for us. Let's look at the first five records by calling the head method. So yeah, we've covered all of these things in previous lectures and it just saves time for me to include these in the notebooks. So let's work with the miles per gallon column which is represented by mpg. Let's see how we can transform its values using normalization and standardization. The first thing I want to do is just plot the values of the mpg columns. So we'll just call the plot function, plt.plot, and we'll pass in our data set, mpg column here. And run this. Okay, and then we have a visualization of the distribution of the data points in the mpg variable. That's what I wanted to create as a baseline to compare this to as we work to transform and normalize the data. So let's start first with normalization. We're going to normalize the values of the mpg column using sklearn's MinMaxScaler function. So we'll first create the object MinMaxScaler class. We'll say minmax_scalar, and we'll set it equal to MinMaxScaler. And then what we want to do is call the MinMaxScaler fit function. So we'll say minmax_scalar.fit, and then we'll pass in the column, mpg. And run this. Now, if we call the MinMaxScaler's transform function and then pass in the mpg variable, this will transform the values of the mpg column so that they are distributed as a series of numbers between zero and one. We'll call it scaled_data, scaled_data. We'll set it equal to minmax_scalar. We'll call the transform method, and we'll pass in our mpg column here. (keyboard taps) And then we'll just go ahead and plot this out so you can see how the data has changed. So to plot it out, we'll use the plot function plt.plot, and we'll pass in our scaled_data. (keyboard taps) And run this. Now, on its face, it looks just like the original plot, but if you look at the y-axis, the values have been rescaled such that they fall between the values of zero and one. Whereas in the original plot, the data points fell between 10 and 35. But there wasn't any distortion in the range of the data points. It looks like the same distribution, but the values of the y-axis have just been scaled. Now, let's standardize the values of the mpg column using scikit-learn's scale function. To do that, we'll say standard_scalar is equal to scale, standard_scalar equal to scale. And then let's pass in our mpg column. So we'll say, dataset mpg. Let's just go ahead and plot this out, plt.plot, and we'll pass in our standard_scalar, and run this. And again, the distribution of the data points looks identical to the previous two charts. But in this plot, we can see that the data points have been rescaled such that they have a mean equal to zero and a standard deviation of one. As with normalization, the data points have not been skewed or distorted in any way. Now that you know how to transform your data sets, you should be ready to get started with basic machine learning algorithms.


Absolutely, let's break down the key concepts from the “Transforming data set distributions” video to enhance your understanding:

Data Transformation: This is the process of changing data from its original format into a different one, making it more suitable for analysis. This can involve cleaning the data, reformatting it, or converting it to a different scale.

Normalization vs. Standardization:

Normalization (Min-Max Scaling): Adjusts the data values to a specific range, typically 0 to 1, without changing the original distribution of the data. This is useful when you need to ensure that all data points are on the same scale, particularly in algorithms that are sensitive to the scale of data.

Standardization: Rescales data to have a mean of 0 and a standard deviation of 1. This method is beneficial because it normalizes the distribution of the data, making it easier to compare different datasets on the same scale.

Practical Application: The video demonstrates how to apply these techniques using Python libraries such as NumPy, pandas, matplotlib, and sklearn. For example, using sklearn's MinMaxScaler for normalization and scale function for standardization. This hands-on demonstration is crucial for understanding how to prepare your dataset for machine learning models.

Choosing Between Techniques: It's important to note that not every dataset requires normalization or standardization. The choice between these techniques depends on your specific dataset and the machine learning algorithm you're using. A practical approach is to experiment with both techniques and the raw data to see which yields the best performance for your model.

Real-world Example with the mtcars Dataset: The video uses the mtcars dataset to show how to transform the “miles per gallon” (mpg) column using both normalization and standardization. This example illustrates the effect of each technique on the data distribution, helping you see the practical implications of data transformation.


Understanding these concepts is crucial for anyone looking to pivot to a Machine Learning Engineer role, as data preprocessing is a foundational step in building effective machine learning models.

